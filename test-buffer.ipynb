{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "import torch\n",
    "from env import HighwayEnv, convert_highd_sample_to_gail_expert\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "from buffer import HighwayEnvMemoryBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.read_csv(r\"D:\\Productivity\\Projects\\High-D\\highd-dataset-v1.0\\data\\26_tracks.csv\")\n",
    "samples = tracks[(tracks.frame>=300*25)&(tracks.frame<=480*25)]\n",
    "samples.to_csv(\"./data/26_sample_tracks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = HighwayEnvMemoryBuffer(300)\n",
    "\n",
    "expert_data, df = convert_highd_sample_to_gail_expert(\n",
    "    sample_csv=r\"./data/26_sample_tracks.csv\",\n",
    "    meta_csv=r\"D:\\Productivity\\Projects\\High-D\\highd-dataset-v1.0\\data\\26_recordingMeta.csv\",\n",
    "    forward=False,\n",
    "    p_agent=0.90\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_STEPS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the environment and set expert data.\n",
    "env = HighwayEnv(dt=0.2, T=50, generation_mode=False, demo_mode=True)\n",
    "# Uncomment and update the following line when expert_data is available:\n",
    "env.set_expert_data(expert_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:04<00:00, 65.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "obs = env.reset() \n",
    "#\n",
    "for step in trange(NUM_STEPS):\n",
    "    # For demonstration, sample random actions for each vehicle slot.\n",
    "    # Action shape: (N_max, 2). Since have set DEMO_MODE=TRUE, the actions will be overwritten by the agents\n",
    "    action = torch.full((env.N_max, 2), 0.0)\n",
    "    # Step the environment: we get new observation, reward, done, and info.\n",
    "    next_obs, reward, done, info = env.step(action)\n",
    "\n",
    "    buffer.push(obs, action, reward, next_obs, done)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, action, reward, next_obs, done = buffer.sample(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 50, 100, 7])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 100])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorNetwork(nn.Module):\n",
    "    def __init__(self, T, M, F, lstm_hidden=64, global_dim=12, combined_hidden=64, output_size=2):\n",
    "        \"\"\"\n",
    "        Actor network for generating vehicle acceleration decisions.\n",
    "        \n",
    "        Parameters:\n",
    "          T (int): History length (number of time steps).\n",
    "          M (int): Maximum number of vehicles per sample.\n",
    "          F (int): Number of features per vehicle per timestep (e.g. [x, y, xVelocity, yVelocity]).\n",
    "          lstm_hidden (int): Hidden dimension for the LSTM.\n",
    "          global_dim (int): Dimension for processing the global inputs (lane markers + road boundaries).\n",
    "          combined_hidden (int): Hidden dimension in the combined FC layers.\n",
    "          output_size (int): Dimension of the acceleration output (typically 2).\n",
    "        \"\"\"\n",
    "        super(ActorNetwork, self).__init__()\n",
    "        self.T = T\n",
    "        self.M = M\n",
    "        self.F = F\n",
    "        self.lstm_hidden = lstm_hidden\n",
    "        \n",
    "        # LSTM to process each vehicle's time-dependent sequence (shape: (T, F)).\n",
    "        self.lstm = nn.LSTM(input_size=F, hidden_size=lstm_hidden, batch_first=True)\n",
    "        \n",
    "        # Global information comes from lane markers (10) and road boundaries (2) => 12 values.\n",
    "        self.global_fc = nn.Linear(12, global_dim)\n",
    "        \n",
    "        # Combined fully connected layers mapping concatenated per-vehicle and global features to the output.\n",
    "        self.combine_fc = nn.Sequential(\n",
    "            nn.Linear(lstm_hidden + global_dim, combined_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(combined_hidden, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, time_dep, lane_markers, boundaries):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        \n",
    "        Parameters:\n",
    "          time_dep (torch.Tensor): Time-dependent kinematics, shape (N, T, M, F).\n",
    "            (Missing entries are NaN; they are replaced by 0 before processing.)\n",
    "          lane_markers (torch.Tensor): Global lane markers, shape (N, 10). May contain NaNs.\n",
    "          boundaries (torch.Tensor): Global road boundaries, shape (N, 2). May contain NaNs.\n",
    "          \n",
    "        Returns:\n",
    "          accelerations (torch.Tensor): Output accelerations of shape (N, M, 2).\n",
    "        \"\"\"\n",
    "        N, T, M, F = time_dep.shape  # Unpack dimensions.\n",
    "        \n",
    "        # --- Process Time-Dependent Kinematics ---\n",
    "        # Rearrange to shape (N, M, T, F), then flatten the N and M dimensions: (N*M, T, F).\n",
    "        time_dep = time_dep.permute(0, 2, 1, 3).contiguous()\n",
    "        time_dep = time_dep.view(N * M, T, F)\n",
    "        \n",
    "        # Compute valid mask for each sequence (valid if not all features are NaN)\n",
    "        valid_mask = ~torch.all(torch.isnan(time_dep), dim=-1)  # shape: (N*M, T)\n",
    "        seq_lengths = valid_mask.sum(dim=1)  # shape: (N*M,)\n",
    "        # Ensure a minimum length of 1 for any sequence.\n",
    "        seq_lengths[seq_lengths == 0] = 1\n",
    "        \n",
    "        # Replace NaN values in the kinematics with 0.\n",
    "        time_dep_clean = torch.nan_to_num(time_dep, nan=0.0)\n",
    "        \n",
    "        # Pack the sequence so that the LSTM ignores padded time steps.\n",
    "        packed = rnn_utils.pack_padded_sequence(time_dep_clean, lengths=seq_lengths.cpu(),\n",
    "                                                  batch_first=True, enforce_sorted=False)\n",
    "        packed_output, (hn, cn) = self.lstm(packed)\n",
    "        # For a single-layer LSTM, hn has shape (1, N*M, lstm_hidden)\n",
    "        hn = hn.squeeze(0)  # Now shape: (N*M, lstm_hidden)\n",
    "        \n",
    "        # Reshape to get per-vehicle representation: (N, M, lstm_hidden)\n",
    "        vehicle_repr = hn.view(N, M, self.lstm_hidden)\n",
    "        \n",
    "        # --- Process Global Information (lane markers and boundaries) ---\n",
    "        # Before processing, replace NaN values in lane markers and boundaries with 0.\n",
    "        # Alternatively, you might choose to use a meaningful default.\n",
    "        lane_markers_clean = torch.nan_to_num(lane_markers, nan=0.0)  # shape: (N, 10)\n",
    "        boundaries_clean = torch.nan_to_num(boundaries, nan=0.0)        # shape: (N, 2)\n",
    "        # Concatenate lane markers and boundaries into a single tensor: shape: (N, 12)\n",
    "        global_input = torch.cat([lane_markers_clean, boundaries_clean], dim=1)\n",
    "        global_info = torch.relu(self.global_fc(global_input))  # shape: (N, global_dim)\n",
    "        # Broadcast to each vehicle slot: shape becomes (N, M, global_dim)\n",
    "        global_info = global_info.unsqueeze(1).expand(-1, M, -1)\n",
    "        \n",
    "        # --- Combine and Generate Accelerations ---\n",
    "        # Concatenate per-vehicle representation with global info along the feature dimension.\n",
    "        combined = torch.cat([vehicle_repr, global_info], dim=-1)  # shape: (N, M, lstm_hidden + global_dim)\n",
    "        # Pass through FC layers to generate acceleration outputs.\n",
    "        accelerations = self.combine_fc(combined)  # shape: (N, M, output_size)\n",
    "        \n",
    "        # Note: even though accelerations has shape (N, M, 2), downstream you should use the agent mask to choose only valid outputs.\n",
    "        return accelerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorNetwork_(nn.Module):\n",
    "    def __init__(self, T, M, F, lstm_hidden=64, global_dim=12, combined_hidden=64, output_size=2):\n",
    "        \"\"\"\n",
    "        Actor network for generating vehicle acceleration decisions.\n",
    "        \n",
    "        Parameters:\n",
    "          T (int): History length (number of time steps).\n",
    "          M (int): Maximum number of vehicles per sample.\n",
    "          F (int): Number of features per vehicle per timestep (e.g. [x, y, xVelocity, yVelocity]).\n",
    "          lstm_hidden (int): Hidden dimension for the LSTM.\n",
    "          global_dim (int): Dimension for processing the global inputs (lane markers + road boundaries).\n",
    "          combined_hidden (int): Hidden dimension in the combined FC layers.\n",
    "          output_size (int): Dimension of the acceleration output (typically 2).\n",
    "        \"\"\"\n",
    "        super(ActorNetwork_, self).__init__()\n",
    "        self.T = T\n",
    "        self.M = M\n",
    "        self.F = F\n",
    "        self.lstm_hidden = lstm_hidden\n",
    "        \n",
    "        # LSTM to process each vehicle's time-dependent sequence (shape: (T, F)).\n",
    "        self.lstm = nn.LSTM(input_size=F, hidden_size=lstm_hidden, batch_first=True)\n",
    "        \n",
    "        # Global information comes from lane markers (10) and road boundaries (2) => 12 values.\n",
    "        # We'll process the lane markers after masking them.\n",
    "        self.global_fc = nn.Linear(10, global_dim)  # process lane markers separately\n",
    "        self.boundary_fc = nn.Linear(2, global_dim)   # process boundaries separately\n",
    "        \n",
    "        # Combine global features (concatenated) and map to final global representation.\n",
    "        self.global_combine_fc = nn.Linear(2 * global_dim, global_dim)\n",
    "        \n",
    "        # Combined fully connected layers mapping concatenated per-vehicle and global features to the output.\n",
    "        self.combine_fc = nn.Sequential(\n",
    "            nn.Linear(lstm_hidden + global_dim, combined_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(combined_hidden, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, time_dep, lane_markers, boundaries):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        \n",
    "        Parameters:\n",
    "          time_dep (torch.Tensor): Time-dependent kinematics, shape (N, T, M, F).\n",
    "            (Missing entries are NaN; they are replaced by 0 before processing.)\n",
    "          lane_markers (torch.Tensor): Global lane markers, shape (N, 10). May contain NaNs.\n",
    "          boundaries (torch.Tensor): Global road boundaries, shape (N, 2). (Assumed to be complete.)\n",
    "          \n",
    "        Returns:\n",
    "          accelerations (torch.Tensor): Output accelerations of shape (N, M, 2).\n",
    "        \"\"\"\n",
    "        N, T, M, F = time_dep.shape  # Unpack dimensions\n",
    "        \n",
    "        # --- Process Time-Dependent Kinematics ---\n",
    "        # Rearrange to shape (N, M, T, F) and flatten to (N*M, T, F)\n",
    "        time_dep = time_dep.permute(0, 2, 1, 3).contiguous().view(N * M, T, F)\n",
    "        \n",
    "        # Compute valid mask: a time step is valid if not all F values are NaN.\n",
    "        valid_mask = ~torch.all(torch.isnan(time_dep), dim=-1)  # (N*M, T)\n",
    "        seq_lengths = valid_mask.sum(dim=1)  # (N*M,)\n",
    "        seq_lengths[seq_lengths == 0] = 1\n",
    "        \n",
    "        # Replace NaNs with 0 in the time-dependent input.\n",
    "        time_dep_clean = torch.nan_to_num(time_dep, nan=0.0)\n",
    "        \n",
    "        # Pack padded sequence and process with LSTM.\n",
    "        packed = rnn_utils.pack_padded_sequence(time_dep_clean, lengths=seq_lengths.cpu(),\n",
    "                                                  batch_first=True, enforce_sorted=False)\n",
    "        packed_output, (hn, cn) = self.lstm(packed)\n",
    "        # hn: (num_layers, N*M, lstm_hidden) → assume single layer and squeeze:\n",
    "        hn = hn.squeeze(0)  # (N*M, lstm_hidden)\n",
    "        \n",
    "        # Reshape vehicle representation to (N, M, lstm_hidden)\n",
    "        vehicle_repr = hn.view(N, M, self.lstm_hidden)\n",
    "        \n",
    "        # --- Process Global Information with Masking for Lane Markers ---\n",
    "        # lane_markers: (N, 10)\n",
    "        # Create a mask for valid lane markers: 1 where not NaN, 0 where NaN.\n",
    "        lane_mask = (~torch.isnan(lane_markers)).float()  # (N, 10)\n",
    "        # Replace NaNs with 0.\n",
    "        lane_markers_clean = torch.nan_to_num(lane_markers, nan=0.0)\n",
    "        # Process lane markers via a linear layer.\n",
    "        global_lane_features = torch.relu(self.global_fc(lane_markers_clean))  # (N, global_dim)\n",
    "        # Scale lane features by the fraction of valid markers.\n",
    "        valid_ratio = lane_mask.mean(dim=1, keepdim=True)  # (N, 1)\n",
    "        global_lane_features = global_lane_features * valid_ratio\n",
    "        \n",
    "        # Process boundaries via another linear layer.\n",
    "        global_boundaries_features = torch.relu(self.boundary_fc(boundaries))  # (N, global_dim)\n",
    "        \n",
    "        # Combine the two global features.\n",
    "        global_combined = torch.cat([global_lane_features, global_boundaries_features], dim=1)  # (N, 2*global_dim)\n",
    "        global_info = torch.relu(self.global_combine_fc(global_combined))  # (N, global_dim)\n",
    "        # Broadcast global_info to each vehicle slot: (N, M, global_dim)\n",
    "        global_info = global_info.unsqueeze(1).expand(-1, M, -1)\n",
    "        \n",
    "        # --- Combine Per-Vehicle and Global Representations ---\n",
    "        combined = torch.cat([vehicle_repr, global_info], dim=-1)  # (N, M, lstm_hidden+global_dim)\n",
    "        accelerations = self.combine_fc(combined)  # (N, M, output_size) (typically 2: [xAccel, yAccel])\n",
    "        \n",
    "        return accelerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = ActorNetwork_(50, 100, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dep, lane_markers, boundaries = obs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 25/1000 [00:00<00:12, 78.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10/1000, Loss: 0.0122\n",
      "Iteration 20/1000, Loss: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 43/1000 [00:00<00:11, 83.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30/1000, Loss: 0.0072\n",
      "Iteration 40/1000, Loss: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 62/1000 [00:00<00:11, 84.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 50/1000, Loss: 0.0030\n",
      "Iteration 60/1000, Loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 80/1000 [00:00<00:10, 86.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 70/1000, Loss: 0.0017\n",
      "Iteration 80/1000, Loss: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 98/1000 [00:01<00:10, 86.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 90/1000, Loss: 0.0005\n",
      "Iteration 100/1000, Loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 126/1000 [00:01<00:09, 89.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 110/1000, Loss: 0.0012\n",
      "Iteration 120/1000, Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 144/1000 [00:01<00:09, 88.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 130/1000, Loss: 0.0005\n",
      "Iteration 140/1000, Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 164/1000 [00:01<00:09, 89.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 150/1000, Loss: 0.0019\n",
      "Iteration 160/1000, Loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 183/1000 [00:02<00:08, 91.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 170/1000, Loss: 0.0016\n",
      "Iteration 180/1000, Loss: 0.0011\n",
      "Iteration 190/1000, Loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 213/1000 [00:02<00:08, 90.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 200/1000, Loss: 0.0020\n",
      "Iteration 210/1000, Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 233/1000 [00:02<00:08, 90.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 220/1000, Loss: 0.0003\n",
      "Iteration 230/1000, Loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 253/1000 [00:02<00:08, 89.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 240/1000, Loss: 0.0002\n",
      "Iteration 250/1000, Loss: 0.0022\n",
      "Iteration 260/1000, Loss: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 283/1000 [00:03<00:07, 90.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 270/1000, Loss: 0.0025\n",
      "Iteration 280/1000, Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 302/1000 [00:03<00:07, 88.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 290/1000, Loss: 0.0004\n",
      "Iteration 300/1000, Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 322/1000 [00:03<00:07, 91.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 310/1000, Loss: 0.0015\n",
      "Iteration 320/1000, Loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 342/1000 [00:03<00:07, 91.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 330/1000, Loss: 0.0030\n",
      "Iteration 340/1000, Loss: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 362/1000 [00:04<00:06, 93.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 350/1000, Loss: 0.0027\n",
      "Iteration 360/1000, Loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 382/1000 [00:04<00:06, 94.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 370/1000, Loss: 0.0007\n",
      "Iteration 380/1000, Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 402/1000 [00:04<00:06, 92.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 390/1000, Loss: 0.0036\n",
      "Iteration 400/1000, Loss: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 422/1000 [00:04<00:06, 90.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 410/1000, Loss: 0.0015\n",
      "Iteration 420/1000, Loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 442/1000 [00:04<00:05, 93.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 430/1000, Loss: 0.0009\n",
      "Iteration 440/1000, Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 462/1000 [00:05<00:05, 91.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 450/1000, Loss: 0.0021\n",
      "Iteration 460/1000, Loss: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 482/1000 [00:05<00:05, 90.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 470/1000, Loss: 0.0019\n",
      "Iteration 480/1000, Loss: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 502/1000 [00:05<00:05, 91.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 490/1000, Loss: 0.0017\n",
      "Iteration 500/1000, Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 522/1000 [00:05<00:05, 92.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 510/1000, Loss: 0.0025\n",
      "Iteration 520/1000, Loss: 0.0013\n",
      "Iteration 530/1000, Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 552/1000 [00:06<00:04, 93.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 540/1000, Loss: 0.0012\n",
      "Iteration 550/1000, Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 572/1000 [00:06<00:04, 87.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 560/1000, Loss: 0.0003\n",
      "Iteration 570/1000, Loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 593/1000 [00:06<00:04, 92.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 580/1000, Loss: 0.0012\n",
      "Iteration 590/1000, Loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 613/1000 [00:06<00:04, 93.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 600/1000, Loss: 0.0002\n",
      "Iteration 610/1000, Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 633/1000 [00:07<00:04, 91.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 620/1000, Loss: 0.0020\n",
      "Iteration 630/1000, Loss: 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 653/1000 [00:07<00:03, 90.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 640/1000, Loss: 0.0003\n",
      "Iteration 650/1000, Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 673/1000 [00:07<00:03, 90.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 660/1000, Loss: 0.0006\n",
      "Iteration 670/1000, Loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 693/1000 [00:07<00:03, 91.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 680/1000, Loss: 0.0015\n",
      "Iteration 690/1000, Loss: 0.0009\n",
      "Iteration 700/1000, Loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 723/1000 [00:08<00:03, 91.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 710/1000, Loss: 0.0013\n",
      "Iteration 720/1000, Loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 743/1000 [00:08<00:02, 91.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 730/1000, Loss: 0.0015\n",
      "Iteration 740/1000, Loss: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 762/1000 [00:08<00:02, 88.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 750/1000, Loss: 0.0011\n",
      "Iteration 760/1000, Loss: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 781/1000 [00:08<00:02, 89.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 770/1000, Loss: 0.0007\n",
      "Iteration 780/1000, Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 801/1000 [00:08<00:02, 91.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 790/1000, Loss: 0.0015\n",
      "Iteration 800/1000, Loss: 0.0008\n",
      "Iteration 810/1000, Loss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 831/1000 [00:09<00:01, 92.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 820/1000, Loss: 0.0006\n",
      "Iteration 830/1000, Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 851/1000 [00:09<00:01, 93.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 840/1000, Loss: 0.0010\n",
      "Iteration 850/1000, Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 871/1000 [00:09<00:01, 90.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 860/1000, Loss: 0.0013\n",
      "Iteration 870/1000, Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 891/1000 [00:09<00:01, 89.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 880/1000, Loss: 0.0014\n",
      "Iteration 890/1000, Loss: 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 911/1000 [00:10<00:00, 90.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 900/1000, Loss: 0.0012\n",
      "Iteration 910/1000, Loss: 0.0003\n",
      "Iteration 920/1000, Loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 941/1000 [00:10<00:00, 89.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 930/1000, Loss: 0.0009\n",
      "Iteration 940/1000, Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 961/1000 [00:10<00:00, 89.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 950/1000, Loss: 0.0023\n",
      "Iteration 960/1000, Loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 981/1000 [00:10<00:00, 91.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 970/1000, Loss: 0.0006\n",
      "Iteration 980/1000, Loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:11<00:00, 90.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 990/1000, Loss: 0.0003\n",
      "Iteration 1000/1000, Loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "actor.train()  # set to training mode\n",
    "\n",
    "# Define an optimizer.\n",
    "optimizer = optim.Adam(actor.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop: We'll do a few iterations updating the network using a fake loss defined as the mean absolute acceleration.\n",
    "num_iterations = 1000\n",
    "for i in trange(num_iterations):\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass.\n",
    "    accel_output = actor(time_dep, lane_markers, boundaries)  # shape (N, M, 2)\n",
    "    # Compute a fake loss: mean of the absolute acceleration values.\n",
    "    loss = torch.abs(accel_output).mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i+1) % 10 == 0:\n",
    "        print(f\"Iteration {i+1}/{num_iterations}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0430, -0.0210],\n",
       "         [-0.0430, -0.0210],\n",
       "         [-0.0430, -0.0210],\n",
       "         ...,\n",
       "         [-0.0430, -0.0210],\n",
       "         [-0.0430, -0.0210],\n",
       "         [-0.0430, -0.0210]],\n",
       "\n",
       "        [[-0.0430, -0.0210],\n",
       "         [-0.0430, -0.0210],\n",
       "         [-0.0430, -0.0210],\n",
       "         ...,\n",
       "         [-0.0430, -0.0210],\n",
       "         [-0.0430, -0.0210],\n",
       "         [-0.0430, -0.0210]],\n",
       "\n",
       "        [[-0.0430, -0.0210],\n",
       "         [-0.0430, -0.0210],\n",
       "         [-0.0430, -0.0210],\n",
       "         ...,\n",
       "         [-0.0430, -0.0210],\n",
       "         [-0.0430, -0.0210],\n",
       "         [-0.0430, -0.0210]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0430, -0.0210],\n",
       "         [-0.0430, -0.0210],\n",
       "         [-0.0430, -0.0210],\n",
       "         ...,\n",
       "         [-0.0430, -0.0210],\n",
       "         [-0.0430, -0.0210],\n",
       "         [-0.0430, -0.0210]],\n",
       "\n",
       "        [[-0.0430, -0.0210],\n",
       "         [-0.0430, -0.0210],\n",
       "         [-0.0430, -0.0210],\n",
       "         ...,\n",
       "         [-0.0430, -0.0210],\n",
       "         [-0.0430, -0.0210],\n",
       "         [-0.0430, -0.0210]],\n",
       "\n",
       "        [[-0.0430, -0.0210],\n",
       "         [-0.0430, -0.0210],\n",
       "         [-0.0430, -0.0210],\n",
       "         ...,\n",
       "         [-0.0430, -0.0210],\n",
       "         [-0.0430, -0.0210],\n",
       "         [-0.0430, -0.0210]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor(obs[0], obs[1], obs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = random.sample(buffer.buffer, 64)\n",
    "states, actions, rewards, next_states, dones = zip(*batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_keys=['time_dependent','time_independent', 'lane_markers', 'boundary_lines', 'agent_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ torch.stack([obs[key] for obs in states]) for key in state_keys ][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mactions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
